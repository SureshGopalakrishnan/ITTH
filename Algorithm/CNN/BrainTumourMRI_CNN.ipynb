{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Brain Tumor MRI : Classification Assignment**\n",
        "\n",
        "---\n",
        "\n",
        "This is a hands-on assignment in **medical image analysis** using deep learning. The objective is to build a robust classification model to accurately identify the type of brain tumor from MRI scans. This is a crucial task that can assist medical professionals in diagnosis.\n",
        "\n",
        "## **Dataset Overview**\n",
        "\n",
        "The dataset, contains over 7,000 brain MRI images. It is well-structured and is divided into two primary folders, `Training` and `Testing`. Each of these folders contains four subfolders, representing the different classes of tumors and healthy brains:\n",
        "\n",
        "* `glioma` : Images of tumors originating from glial cells.\n",
        "* `meningioma` : Images of tumors arising from the meninges.\n",
        "* `notumor` : Images of healthy brains with no tumor present.\n",
        "* `pituitary` : Images of tumors located in the pituitary gland.\n",
        "\n",
        "The images are in JPEG format and vary in size and resolution, which will require preprocessing before being used for model training.\n",
        "\n",
        "## **Assignment Objectives**\n",
        "\n",
        "The main objective of this assignment is to build and evaluate a **Convolutional Neural Network (CNN)** for multi-class image classification. The key goals are:\n",
        "\n",
        "1.  **Data Loading and Preprocessing**  \n",
        "Effectively load images from the directory structure and perform necessary preprocessing steps, such as resizing, converting to grayscale, and normalizing pixel values.\n",
        "2.  **Model Architecture**  \n",
        "Design and implement a CNN model suitable for image classification.\n",
        "3.  **Model Training**  \n",
        "Train the CNN model on the `Training` dataset.\n",
        "4.  **Model Evaluation**  \n",
        "Evaluate the trained model's performance on the `Testing` dataset using a confusion matrix and classification report.\n",
        "5.  **Bonus (If time permits)**  \n",
        "Implement data augmentation techniques to improve model generalization.\n",
        "\n",
        "## **Key Concepts**\n",
        "\n",
        "* **Deep Learning**  \n",
        "Understanding the fundamentals of neural networks and their application in image analysis.\n",
        "* **Convolutional Neural Networks (CNNs)**  \n",
        "Learning how convolutional, pooling, and dense layers work together to extract features from images.\n",
        "* **Image Preprocessing**  \n",
        "Knowledge of techniques to prepare image data for a neural network.\n",
        "* **Multi-class Classification**  \n",
        "Training a model to predict one of four possible classes.\n",
        "* **Model Evaluation**  \n",
        "Using appropriate metrics to assess model performance on unseen data."
      ],
      "metadata": {
        "id": "8YwM4SK5Zsnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initial Setup**"
      ],
      "metadata": {
        "id": "S-nzKJhHUD9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime"
      ],
      "metadata": {
        "id": "G1DjKDm6Ro14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Magic command to get the elpased time for each cell\n",
        "#\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "93-uSh-bOl-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFqGUk-0Yc99"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Import Libraries\n",
        "#\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "\n",
        "import random\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "#\n",
        "# Suppress the UserWarning from Pillow (PIL)\n",
        "#\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category = UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Set Pandas display format for floats\n",
        "#\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "#\n",
        "# Set NumPy's print options to suppress scientific notation and set precision.\n",
        "# 'suppress  = True' - Prevents the use of scientific notation.\n",
        "# 'precision = 2'    - Sets the number of decimal places to display.\n",
        "#\n",
        "np.set_printoptions(suppress = True, precision = 2)"
      ],
      "metadata": {
        "id": "vGk-aDLdoKd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Upload the dataset 'BrainTumourMRI.zip'\n",
        "#\n",
        "# Absolute Filename = /content/BrainTumourMRI.zip\n",
        "#\n",
        "uploadOutput = files.upload()"
      ],
      "metadata": {
        "id": "rg15ygKjbLuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**\n",
        "**Note**  \n",
        "Before running this cell, please ensure you have uploaded the `BrainTumourMRI.zip` file to your working directory.\n",
        "\n",
        "This script first defines the directory structure and the categories for the dataset. It then proceeds to load the images and their corresponding labels for both the training and testing sets. The images are loaded as raw PIL (Pillow) objects and their labels are stored as integers representing the category index."
      ],
      "metadata": {
        "id": "63YjYNiue83T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Extract zip file\n",
        "#\n",
        "\n",
        "#\n",
        "# Define the path to the zipped dataset file\n",
        "#\n",
        "ZIP_FILE_PATH  = '/content/BrainTumourMRI.zip'\n",
        "EXTRACTION_DIR = '/content/'\n",
        "\n",
        "#\n",
        "# Unzip the dataset file\n",
        "#\n",
        "try:\n",
        "  with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "    print(f\"Extracting contents from '{ZIP_FILE_PATH}'...\")\n",
        "    zip_ref.extractall(EXTRACTION_DIR)\n",
        "\n",
        "  print(\"Extraction complete!\")\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: The file '{ZIP_FILE_PATH}' was not found.\")\n",
        "  print(\"Please ensure the file is uploaded to the specified path.\")\n",
        "  exit()"
      ],
      "metadata": {
        "id": "hZSLXcJTfATK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Load Data\n",
        "#\n",
        "EXTRACTED_DIR = 'Brain Tumour MRI'\n",
        "BASE_DATA_DIR = os.path.join(EXTRACTION_DIR, EXTRACTED_DIR)\n",
        "CATEGORIES    = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "print(BASE_DATA_DIR)\n",
        "print(CATEGORIES)"
      ],
      "metadata": {
        "id": "tHtIleuClqX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Function to load the raw images and labels\n",
        "#\n",
        "def loadRawData(dataType):\n",
        "    #\n",
        "    # Loads raw PIL Image objects and their labels from a specified directory\n",
        "    #\n",
        "    # Parameters:\n",
        "    #     dataType (str): Either 'Training' or 'Testing'\n",
        "    #\n",
        "    # Returns:\n",
        "    #     tuple: A tuple containing two lists (images, labels)\n",
        "    #\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    dataPath = os.path.join(BASE_DATA_DIR, dataType)\n",
        "\n",
        "    #\n",
        "    # Check, if the data path directory exists\n",
        "    #\n",
        "    if not os.path.isdir(dataPath):\n",
        "      print(f\"Directory not found: {dataPath}. Skipping.\")\n",
        "      return images, labels\n",
        "\n",
        "    #\n",
        "    # Check and load images and labels for categories\n",
        "    #\n",
        "    for category in CATEGORIES:\n",
        "      categoryPath = os.path.join(dataPath, category)\n",
        "      labelIndex   = CATEGORIES.index(category)\n",
        "\n",
        "      #\n",
        "      # Check, if the data path directory exists\n",
        "      #\n",
        "      if not os.path.isdir(categoryPath):\n",
        "        print(f\"Directory not found: {categoryPath}. Skipping.\")\n",
        "        continue # Continue with the next category\n",
        "\n",
        "      #\n",
        "      # Loop through the category and load every JPEG file\n",
        "      #\n",
        "      for fileName in os.listdir(categoryPath):\n",
        "        #\n",
        "        # Check, if it is a JPEG file\n",
        "        #\n",
        "        if fileName.endswith('.jpg'):\n",
        "          filePath = os.path.join(categoryPath, fileName)\n",
        "\n",
        "          try:\n",
        "            #\n",
        "            # Open the image as a raw PIL object\n",
        "            #\n",
        "            thisImage = Image.open(filePath)\n",
        "            images.append(thisImage)\n",
        "            labels.append(labelIndex)\n",
        "          except Exception as e:\n",
        "            print(f\"Could not load image {filePath}: {e}\")\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "0y_ZwMxCFnIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Load Training Data\n",
        "#\n",
        "DATATYPE = 'Training'\n",
        "X_train, y_train = loadRawData(DATATYPE)\n",
        "\n",
        "#\n",
        "# Load Testing Data\n",
        "#\n",
        "DATATYPE = 'Testing'\n",
        "X_test, y_test = loadRawData(DATATYPE)\n",
        "\n",
        "print(\"Dataset Loading Summary\")\n",
        "print(\"=======================\")\n",
        "print(f\"Number of training images loaded : {len(X_train)}\")\n",
        "print(f\"Number of training labels loaded : {len(y_train)}\")\n",
        "print(f\"Number of testing images loaded  : {len(X_test)}\" )\n",
        "print(f\"Number of testing labels loaded  : {len(y_test)}\" )"
      ],
      "metadata": {
        "id": "72VKQ_5zKL_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:5]"
      ],
      "metadata": {
        "id": "AQplMDDLqeOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:5]"
      ],
      "metadata": {
        "id": "fhMMg9rnqlDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:5]"
      ],
      "metadata": {
        "id": "OUTqvpltqpLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "id": "qIdFwnxgqrwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualisation**  \n",
        "Now that the data is loaded, it is good practice to visualize some samples to ensure that everything is correct. The following blocks will display a random image from each of the four categories, along with its label.\n"
      ],
      "metadata": {
        "id": "wOQZBHljT4rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# First image\n",
        "#\n",
        "X_train[0]"
      ],
      "metadata": {
        "id": "ZaayyvNaR3qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Create a dictionary to store one random image per category for visualization\n",
        "#\n",
        "randomImages = {}\n",
        "\n",
        "#\n",
        "# OPTIMIZATION\n",
        "# Create a more efficient lookup table for each category\n",
        "#\n",
        "# This avoids iterating through all labels multiple times. Instead, we\n",
        "# build this mapping once and then use it for fast lookups\n",
        "#\n",
        "# This is a much more performant way to handle large datasets\n",
        "#\n",
        "categoryIndices = {category: [] for category in CATEGORIES}\n",
        "\n",
        "for i, label in enumerate(y_train):\n",
        "    categoryName = CATEGORIES[label]\n",
        "    categoryIndices[categoryName].append(i)\n",
        "\n",
        "#\n",
        "# Loop through our predefined CATEGORIES list to ensure we get an image\n",
        "# for each one\n",
        "#\n",
        "for category, indices in categoryIndices.items():\n",
        "  #\n",
        "  # If the list of indices for the current category is not empty,\n",
        "  # we select a random index from it.\n",
        "  #\n",
        "  # If indices is a non-empty list, Python considers it \"truthy\" and the 'if'\n",
        "  # is executed\n",
        "  #\n",
        "  if indices:\n",
        "    randomIndex = random.choice(indices)\n",
        "    randomImages[category] = X_train[randomIndex] # Populate the dictionary\n",
        "\n",
        "#\n",
        "# Create a figure to display the images\n",
        "#\n",
        "plt.figure(figsize = (15, 8))\n",
        "plt.suptitle(\"Random Sample Images from Each Category\", fontsize = 18, fontweight = 'bold')\n",
        "plt.tight_layout(pad = 3.0) # Adjust padding between subplots\n",
        "\n",
        "#\n",
        "# Loop through the dictionary and display each image\n",
        "#\n",
        "for i, (category, image) in enumerate(randomImages.items()):\n",
        "    ax = plt.subplot(1, len(CATEGORIES), i + 1)\n",
        "    ax.imshow(image, cmap = 'gray') # Brain MRIs are typically grayscale\n",
        "    ax.set_title(f\"Label: {category}\\nShape: {image.size}\", fontsize = 12)\n",
        "    ax.axis('off') # Hide the axes\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yYFo5HapY6j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing**\n",
        "**This also includes Normalisation**"
      ],
      "metadata": {
        "id": "L8YeLlFlnpaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Define image size\n",
        "#\n",
        "IMAGE_SIZE = 128"
      ],
      "metadata": {
        "id": "kbZFCm6Gnr4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Function to pre-process the images\n",
        "#\n",
        "# NOTE - This dataset is not the same format as cifar10, which is already\n",
        "#        an numpy array\n",
        "#\n",
        "def preProcessImages(imageList):\n",
        "  #\n",
        "  # Preprocesses a list of PIL Image objects for model training\n",
        "  #\n",
        "  # Parameters:\n",
        "  #   imageList (list): A list of PIL Image objects\n",
        "  #\n",
        "  # Returns:\n",
        "  #   np.array: A NumPy array of pre-processed images\n",
        "  #\n",
        "\n",
        "  #\n",
        "  # Create an empty list to hold the pre-processed images\n",
        "  #\n",
        "  processedImages = []\n",
        "\n",
        "  for thisImage in imageList:\n",
        "    #\n",
        "    # Resize the image to a consistent size (128x128 pixels)\n",
        "    #\n",
        "    # This is a critical step because CNNs require all input images to have\n",
        "    # the exact same dimensions. Our raw images vary in size.\n",
        "    #\n",
        "    imageResized = thisImage.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "    #\n",
        "    # Convert the image to a single-channel grayscale format ('L')\n",
        "    #\n",
        "    # An MRI scan is fundamentally a grayscale image\n",
        "    # The different shades of gray represent varying tissue densities, which is\n",
        "    # what allows a doctor (or a CNN) to see a tumor\n",
        "    #\n",
        "    # If we convert these images to a binary \"black and white\" format,\n",
        "    # we would lose all of that rich, subtle information and the model would\n",
        "    # likely perform very poorly\n",
        "    #\n",
        "    # This is the crucial fix for the ValueError. Some of our images are\n",
        "    # likely in RGB format, which would result in a shape of (128, 128, 3).\n",
        "    # By converting them all to grayscale, we ensure a consistent shape of\n",
        "    # (128, 128) for every image before we add the channel dimension.\n",
        "    #\n",
        "    imageGrayscale = imageResized.convert('L')\n",
        "\n",
        "    #\n",
        "    # Convert the resized PIL Image object into a NumPy array\n",
        "    #\n",
        "    # This is necessary because TensorFlow models operate on NumPy arrays,\n",
        "    # not on PIL Image objects. This is the main difference from datasets\n",
        "    # like CIFAR-10 which are already provided in NumPy array format.\n",
        "    #\n",
        "    imageArray = np.array(imageGrayscale)\n",
        "\n",
        "    #\n",
        "    # Expand dimensions to add the channel axis\n",
        "    #\n",
        "    # Our images are grayscale, with a shape of (128, 128). CNNs, especially\n",
        "    # in frameworks like TensorFlow, expect a channel dimension\n",
        "    # For grayscale images, the shape should be (128, 128, 1)\n",
        "    # This line adds that last dimension.\n",
        "    #\n",
        "    imageArray = np.expand_dims(imageArray, axis = -1)\n",
        "\n",
        "    #\n",
        "    # Add the processed image to the list\n",
        "    #\n",
        "    processedImages.append(imageArray)\n",
        "\n",
        "  #\n",
        "  # Convert the list of arrays to a single NumPy array.\n",
        "  #\n",
        "  # We now have a list of individual image arrays, which we need to stack\n",
        "  # into a single, cohesive NumPy array to feed into the model.\n",
        "  #\n",
        "  processedImages = np.array(processedImages)\n",
        "\n",
        "  #\n",
        "  # Normalize the pixel values to a range of [0, 1]\n",
        "  #\n",
        "  # This is a standard and crucial step in deep learning. Normalizing the\n",
        "  # data helps the model converge faster and improves its overall performance\n",
        "  #\n",
        "  # We are dividing by 255.0 because the pixel values are in the range of\n",
        "  # 0 to 255\n",
        "  #\n",
        "  # We can also use 255 but 255.0 is considered to be best practice\n",
        "  #\n",
        "  return processedImages / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "10TSwxECsRTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Preprocess the training and testing images\n",
        "# It matches with what we have seen in cifar10 images\n",
        "#\n",
        "X_train_processed = preProcessImages(X_train)\n",
        "X_test_processed  = preProcessImages(X_test)\n",
        "\n",
        "print(\"Data Preprocessing Summary\")\n",
        "print(\"==========================\")\n",
        "print(f\"Shape of preprocessed training images : {X_train_processed.shape}\")\n",
        "print(f\"Shape of preprocessed testing images  : {X_test_processed.shape}\")"
      ],
      "metadata": {
        "id": "cuGx8_j0H3fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# One-Hot Encode the labels\n",
        "#\n",
        "# We are using 'to_categorical' to convert our integer labels (e.g., 0, 1, 2, 3)\n",
        "# into a one-hot encoded format (e.g., [1,0,0,0], [0,1,0,0], etc.).\n",
        "#\n",
        "# This is a requirement for the 'categorical_crossentropy' loss function\n",
        "# which is commonly used for multi-class classification\n",
        "#\n",
        "# The alternative, 'sparse_categorical_crossentropy', would allow us to skip\n",
        "# this step, but 'to_categorical' makes the output shape of the model more\n",
        "# explicit and is a common practice and also we've done this in cifar10\n",
        "#\n",
        "# For our four categories:\n",
        "#   glioma     (which we represent as 0) becomes [1., 0., 0., 0.]\n",
        "#   meningioma (which is 1)              becomes [0., 1., 0., 0.]\n",
        "#   notumor    (which is 2)              becomes [0., 0., 1., 0.]\n",
        "#   pituitary  (which is 3)              becomes [0., 0., 0., 1.]\n",
        "#\n",
        "y_train_encoded = to_categorical(y_train, num_classes = len(CATEGORIES))\n",
        "y_test_encoded  = to_categorical(y_test,  num_classes = len(CATEGORIES))\n",
        "\n",
        "print(\"Data Preprocessing Summary\")\n",
        "print(\"==========================\")\n",
        "print(f\"Shape of one-hot encoded training labels : {y_train_encoded.shape}\")\n",
        "print(f\"Shape of one-hot encoded testing labels  : {y_test_encoded.shape}\")\n"
      ],
      "metadata": {
        "id": "MfnKXFJqPbyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Print the shapes of the preprocessed data to confirm\n",
        "#\n",
        "print(\"Data Preprocessing Summary\")\n",
        "print(\"==========================\")\n",
        "print(f\"Shape of preprocessed training images    : {X_train_processed.shape}\")\n",
        "print(f\"Shape of one-hot encoded training labels : {y_train_encoded.shape}\")\n",
        "print(f\"Shape of preprocessed testing images     : {X_test_processed.shape}\")\n",
        "print(f\"Shape of one-hot encoded testing labels  : {y_test_encoded.shape}\")"
      ],
      "metadata": {
        "id": "HqOLgJZLQ5Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Building - Part 01**"
      ],
      "metadata": {
        "id": "i-C_QpcHU_bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Define the CNN architecture\n",
        "#\n",
        "NUMBER_OF_NEURONS = 512\n",
        "numberOfClasses   = len(CATEGORIES)\n",
        "\n",
        "cnnModelInitial = models.Sequential(\n",
        "                                     [\n",
        "                                       #\n",
        "                                       # First Convolutional Block\n",
        "                                       # Convolution -> Activation -> Pooling\n",
        "                                       #\n",
        "                                       # This block learns to detect basic features like edges and curves\n",
        "                                       #\n",
        "                                       # The Conv2D layer applies 32 filters of size 3x3 to the input images\n",
        "                                       # 'relu' is the activation function that introduces non-linearity\n",
        "                                       # 'input_shape' is specified for the first layer to define the\n",
        "                                       # dimensions of our input images (128x128 pixels, 1 channel for grayscale)\n",
        "                                       #\n",
        "                                       layers.Conv2D(\n",
        "                                                      filters     = 32,\n",
        "                                                      kernel_size = (3, 3),\n",
        "                                                      activation  = 'relu',\n",
        "                                                      input_shape = (IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "                                                    ),\n",
        "                                       #\n",
        "                                       # MaxPooling2D downsamples the feature maps, reducing the dimensionality\n",
        "                                       #\n",
        "                                       # This helps in reducing computation and preventing overfitting\n",
        "                                       # It takes the maximum value in each 2x2 window.\n",
        "                                       #\n",
        "                                       # NOTE - MaxPooling2D and MaxPool2D are exactly the same\n",
        "                                       #        MaxPool2D belongs to old Keras and now it's an\n",
        "                                       #        alias for MaxPooling2D\n",
        "                                       #\n",
        "                                       layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "                                       #\n",
        "                                       # Second Convolutional Block\n",
        "                                       # Convolution -> Activation -> Pooling\n",
        "                                       #\n",
        "                                       # This block learns more complex features. We double the number of filters\n",
        "                                       # to allow the model to learn a richer representation.\n",
        "                                       #\n",
        "                                       layers.Conv2D(\n",
        "                                                      filters     = 64,\n",
        "                                                      kernel_size = (3, 3),\n",
        "                                                      activation  = 'relu'\n",
        "                                                    ),\n",
        "                                       layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "                                       #\n",
        "                                       # Third Convolutional Block\n",
        "                                       # Convolution -> Activation -> Pooling\n",
        "                                       #\n",
        "                                       # We add a third block with 128 filters to capture even more abstract features.\n",
        "                                       #\n",
        "                                       layers.Conv2D(\n",
        "                                                      filters     = 128,\n",
        "                                                      kernel_size = (3, 3),\n",
        "                                                      activation  = 'relu'\n",
        "                                                    ),\n",
        "                                       layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "                                       #\n",
        "                                       # Classification Head: Flatten -> Dense -> Output\n",
        "                                       #\n",
        "\n",
        "                                       #\n",
        "                                       # Flatten Layer\n",
        "                                       #\n",
        "                                       # This layer converts the 2D feature maps from the previous layers into\n",
        "                                       # a 1D vector. This is necessary because the dense layers expect\n",
        "                                       # a one-dimensional input.\n",
        "                                       #\n",
        "                                       layers.Flatten(),\n",
        "\n",
        "                                       #\n",
        "                                       # Dense Layers / Fully Connected Layers\n",
        "                                       #\n",
        "                                       # The dense layers perform the actual classification based on the features\n",
        "                                       # extracted by the convolutional blocks.\n",
        "                                       #\n",
        "                                       # The first dense layer has 512 neurons with 'relu' activation.\n",
        "                                       # It acts as a hidden layer.\n",
        "                                       #\n",
        "                                       layers.Dense(\n",
        "                                                     NUMBER_OF_NEURONS,\n",
        "                                                     activation = 'relu'\n",
        "                                                   ),\n",
        "\n",
        "                                       #\n",
        "                                       # Output Layer\n",
        "                                       #\n",
        "                                       # This is the final layer.\n",
        "                                       # It has 4 neurons, one for each of our tumor categories\n",
        "                                       #\n",
        "                                       # The 'softmax' activation function converts the raw output\n",
        "                                       # scores into a probability distribution, where the sum of\n",
        "                                       # probabilities for all categories equals 1.\n",
        "                                       # The highest probability indicates the model's\n",
        "                                       # predicted class.\n",
        "                                       #\n",
        "                                       layers.Dense(\n",
        "                                                     numberOfClasses,\n",
        "                                                     activation = 'softmax'\n",
        "                                                   )\n",
        "                                     ]\n",
        "                                   )"
      ],
      "metadata": {
        "id": "KAH87lOQVCje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Compile the CNN Model\n",
        "#\n",
        "\n",
        "#\n",
        "# 'adam' is a popular and efficient optimizer.\n",
        "# 'categorical_crossentropy' is the standard loss function for multi-class\n",
        "# classification problems with one-hot encoded labels.\n",
        "# 'accuracy' is the metric we'll use to monitor performance during training.\n",
        "#\n",
        "cnnModelInitial.compile(\n",
        "                         optimizer = 'adam', # 'Adam'/'ADAM' works too, but like 'relu' lowercase is the standard\n",
        "                         loss      = 'categorical_crossentropy',\n",
        "                         metrics   = ['accuracy']\n",
        "                       )"
      ],
      "metadata": {
        "id": "6H2HxwculKSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Print the model summary\n",
        "#\n",
        "# This gives us a detailed view of the model's architecture, including the\n",
        "# output shape and the number of parameters for each layer.\n",
        "#\n",
        "cnnModelInitial.summary()"
      ],
      "metadata": {
        "id": "RGa8ouGtpkfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training (Fitting)**"
      ],
      "metadata": {
        "id": "1sYqmUKurrBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Define key training parameters\n",
        "#\n",
        "EPOCHS     = 20 # Number of times the entire dataset is passed through the network\n",
        "BATCH_SIZE = 32 # Number of samples processed before the model's weights are updated"
      ],
      "metadata": {
        "id": "wGZKEy-Grs08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Starting model training for {EPOCHS} epochs...\")\n",
        "print(\"===============================================\")\n",
        "\n",
        "#\n",
        "# Fit the model to the training data\n",
        "#\n",
        "# model.fit() executes the training process\n",
        "#\n",
        "# The input arguments are:\n",
        "# - X_train_processed : The preprocessed image data (features).\n",
        "# - y_train_encoded   : The one-hot encoded labels (targets).\n",
        "# - epochs            : The total number of iterations over the training set.\n",
        "# - batch_size        : The number of samples per gradient update.\n",
        "# - validation_split  : We reserve 20% of the training data to monitor\n",
        "#                       the model's performance on unseen data during training,\n",
        "#                       which helps detect overfitting early.\n",
        "# - verbose           : Sets the level of detail displayed during training (1 = progress bar).\n",
        "#\n",
        "trainingHistoryInitial = cnnModelInitial.fit(\n",
        "                                              X_train_processed,\n",
        "                                              y_train_encoded,\n",
        "                                              epochs           = EPOCHS,\n",
        "                                              batch_size       = BATCH_SIZE,\n",
        "                                              validation_split = 0.2, # Use 20% of training data for validation\n",
        "                                              verbose          = 1\n",
        "                                            )\n",
        "\n",
        "print(\"Model training complete!\")\n",
        "print(\"Training history is stored in the 'trainingHistoryInitial' variable\")"
      ],
      "metadata": {
        "id": "vpZXA3X3QgPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Displaying a brief summary of the final training results\n",
        "#\n",
        "print(trainingHistoryInitial.history)\n",
        "print(\"======================\")\n",
        "print(\"Final Training Summary\")\n",
        "print(\"======================\")\n",
        "print(f\"Final Training Loss       : {trainingHistoryInitial.history['loss'][-1]:.4f}\"        )\n",
        "print(f\"Final Training Accuracy   : {trainingHistoryInitial.history['accuracy'][-1]:.4f}\"    )\n",
        "print(f\"Final Validation Loss     : {trainingHistoryInitial.history['val_loss'][-1]:.4f}\"    )\n",
        "print(f\"Final Validation Accuracy : {trainingHistoryInitial.history['val_accuracy'][-1]:.4f}\")"
      ],
      "metadata": {
        "id": "CAWH0rMCSd8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observation on Model**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "These results show a **classic and severe case of overfitting**, meaning the model has perfectly learned the training examples but is failing to generalize that knowledge to new, unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Observation: The Large Performance Gap (High Variance)**\n",
        "\n",
        "The critical issue is the massive difference between **Training Accuracy** and **Validation Accuracy**:\n",
        "\n",
        "- **Training Accuracy:** `1.0000` (100%)  \n",
        "- **Validation Accuracy:** `0.9116` (91.16%)  \n",
        "\n",
        "A 100% training accuracy indicates the model has essentially **memorized the entire training set**, including noise or irrelevant details.  \n",
        "When tested on validation data, performance drops by nearly **9 percentage points**, showing high variance and poor generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### **Interpretation of Loss Values**\n",
        "\n",
        "The loss values confirm the severity of the overfitting:\n",
        "\n",
        "- **Training Loss:** `0.0001` (near zero)  \n",
        "  → The model is extremely confident in its predictions on the training set.  \n",
        "\n",
        "- **Validation Loss:** `0.6109` (high)  \n",
        "  → Even when the model predicts correctly, it is **not confident** on unseen data.  \n",
        "  → When it predicts wrong, it is often **spectacularly wrong**.  \n",
        "\n",
        "This contrast between training and validation losses clearly demonstrates poor generalization ability.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "The model is **over-complicated** or has been **trained too long** (too many epochs) relative to the dataset size/complexity.\n",
        "\n",
        "---\n",
        "\n",
        "### **Next Steps to Fix Overfitting**\n",
        "\n",
        "1. **Implement Early Stopping**  \n",
        "   - Stop training automatically when `val_loss` begins to rise.  \n",
        "   - Save weights from the **best epoch**.  \n",
        "\n",
        "2. **Add Dropout Layers**  \n",
        "   - Introduce dropout after convolution/pooling layers.  \n",
        "   - Forces the network to learn more **robust, generalizable features**.  \n",
        "\n",
        "3. **Data Augmentation**  \n",
        "   - Expand dataset variability with random **rotations, flips, and shifts**.  \n",
        "   - Makes the model more robust to real-world variations.  "
      ],
      "metadata": {
        "id": "Ryv3rp1Wmbon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Evaluate model for comparison\n",
        "#\n",
        "lossInitial, accuracyInitial = cnnModelInitial.evaluate(\n",
        "                                                         X_test_processed,\n",
        "                                                         y_test_encoded,\n",
        "                                                         verbose = 1\n",
        "                                                       )\n",
        "\n",
        "print(\"Initial Model Evaluation\")\n",
        "print(\"========================\")\n",
        "print(f\"Test Loss    : {lossInitial:.4f}\"    )\n",
        "print(f\"Test Accuracy: {accuracyInitial:.4f}\")"
      ],
      "metadata": {
        "id": "vP535rXHAWdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Building - Part 02**"
      ],
      "metadata": {
        "id": "Dq4fczOipSmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Define the CNN architecture\n",
        "#\n",
        "NUMBER_OF_NEURONS = 512\n",
        "numberOfClasses   = len(CATEGORIES)\n",
        "\n",
        "cnnModelRegularised = models.Sequential(\n",
        "                                         [\n",
        "                                           #\n",
        "                                           # First Convolutional Block\n",
        "                                           # Convolution -> Activation -> Pooling\n",
        "                                           #\n",
        "                                           # This block learns to detect basic features like edges and curves\n",
        "                                           #\n",
        "                                           # The Conv2D layer applies 32 filters of size 3x3 to the input images\n",
        "                                           # 'relu' is the activation function that introduces non-linearity\n",
        "                                           # 'input_shape' is specified for the first layer to define the\n",
        "                                           # dimensions of our input images (128x128 pixels, 1 channel for grayscale)\n",
        "                                           #\n",
        "                                           layers.Conv2D(\n",
        "                                                          filters     = 32,\n",
        "                                                          kernel_size = (3, 3),\n",
        "                                                          activation  = 'relu',\n",
        "                                                          input_shape = (IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "                                                        ),\n",
        "                                           #\n",
        "                                           # MaxPooling2D downsamples the feature maps, reducing the dimensionality\n",
        "                                           #\n",
        "                                           # This helps in reducing computation and preventing overfitting\n",
        "                                           # It takes the maximum value in each 2x2 window.\n",
        "                                           #\n",
        "                                           # NOTE - MaxPooling2D and MaxPool2D are exactly the same\n",
        "                                           #        MaxPool2D belongs to old Keras and now it's an\n",
        "                                           #        alias for MaxPooling2D\n",
        "                                           #\n",
        "                                           layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "                                           #\n",
        "                                           # NEW REGULARIZATION: Dropout Layer\n",
        "                                           # Randomly sets 25% of the input units to 0 at each update\n",
        "                                           # during training. This prevents neurons from co-adapting,\n",
        "                                           # forcing the network to learn more robust features.\n",
        "                                           #\n",
        "                                           layers.Dropout(0.25),\n",
        "\n",
        "                                           #\n",
        "                                           # Second Convolutional Block\n",
        "                                           # Convolution -> Activation -> Pooling\n",
        "                                           #\n",
        "                                           # This block learns more complex features. We double the number of filters\n",
        "                                           # to allow the model to learn a richer representation.\n",
        "                                           #\n",
        "                                           layers.Conv2D(\n",
        "                                                          filters     = 64,\n",
        "                                                          kernel_size = (3, 3),\n",
        "                                                          activation  = 'relu'\n",
        "                                                        ),\n",
        "                                           layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "                                           #\n",
        "                                           # NEW REGULARIZATION: Second Dropout Layer\n",
        "                                           #\n",
        "                                           layers.Dropout(0.25),\n",
        "\n",
        "                                           #\n",
        "                                           # Third Convolutional Block\n",
        "                                           # Convolution -> Activation -> Pooling\n",
        "                                           #\n",
        "                                           # We add a third block with 128 filters to capture even more abstract features.\n",
        "                                           #\n",
        "                                           layers.Conv2D(\n",
        "                                                          filters     = 128,\n",
        "                                                          kernel_size = (3, 3),\n",
        "                                                          activation  = 'relu'\n",
        "                                                        ),\n",
        "                                           layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "                                           #\n",
        "                                           # Classification Head: Flatten -> Dense -> Output\n",
        "                                           #\n",
        "\n",
        "                                           #\n",
        "                                           # Flatten Layer\n",
        "                                           #\n",
        "                                           # This layer converts the 2D feature maps from the previous layers into\n",
        "                                           # a 1D vector. This is necessary because the dense layers expect\n",
        "                                           # a one-dimensional input.\n",
        "                                           #\n",
        "                                           layers.Flatten(),\n",
        "\n",
        "                                           #\n",
        "                                           # Dense Layers / Fully Connected Layers\n",
        "                                           #\n",
        "                                           # The dense layers perform the actual classification based on the features\n",
        "                                           # extracted by the convolutional blocks.\n",
        "                                           #\n",
        "                                           # The first dense layer has 512 neurons with 'relu' activation.\n",
        "                                           # It acts as a hidden layer.\n",
        "                                           #\n",
        "                                           layers.Dense(\n",
        "                                                         NUMBER_OF_NEURONS,\n",
        "                                                         activation = 'relu'\n",
        "                                                       ),\n",
        "\n",
        "                                           #\n",
        "                                           # Output Layer\n",
        "                                           #\n",
        "                                           # This is the final layer.\n",
        "                                           # It has 4 neurons, one for each of our tumor categories\n",
        "                                           #\n",
        "                                           # The 'softmax' activation function converts the raw output\n",
        "                                           # scores into a probability distribution, where the sum of\n",
        "                                           # probabilities for all categories equals 1.\n",
        "                                           # The highest probability indicates the model's\n",
        "                                           # predicted class.\n",
        "                                           #\n",
        "                                           layers.Dense(\n",
        "                                                         numberOfClasses,\n",
        "                                                         activation = 'softmax'\n",
        "                                                       )\n",
        "                                         ]\n",
        "                                       )"
      ],
      "metadata": {
        "id": "9eWPLx4SpWfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Compile the CNN Model\n",
        "#\n",
        "\n",
        "#\n",
        "# 'adam' is a popular and efficient optimizer.\n",
        "# 'categorical_crossentropy' is the standard loss function for multi-class\n",
        "# classification problems with one-hot encoded labels.\n",
        "# 'accuracy' is the metric we'll use to monitor performance during training.\n",
        "#\n",
        "cnnModelRegularised.compile(\n",
        "                             optimizer = 'adam',                     # 'Adam'/'ADAM' works too, but like 'relu' lowercase is the standard\n",
        "                             loss      = 'categorical_crossentropy', # Standard for multi-class classification\n",
        "                             metrics   = ['accuracy']\n",
        "                           )"
      ],
      "metadata": {
        "id": "64O68Lvqp1b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Print the model summary\n",
        "#\n",
        "# This gives us a detailed view of the model's architecture, including the\n",
        "# output shape and the number of parameters for each layer.\n",
        "#\n",
        "cnnModelRegularised.summary()"
      ],
      "metadata": {
        "id": "hzg9yJXJqFFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training (Fitting) and Early Stopping**"
      ],
      "metadata": {
        "id": "Nzm_Ez6bnjeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Define key training parameters\n",
        "#\n",
        "EPOCHS     = 20 # Number of times the entire dataset is passed through the network\n",
        "BATCH_SIZE = 32 # Number of samples processed before the model's weights are updated"
      ],
      "metadata": {
        "id": "Ycr7NPi_rhJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# NEW REGULARIZATION: Early Stopping Callback\n",
        "#\n",
        "# This callback is essential for mitigating overfitting. It monitors the\n",
        "# 'val_loss' (validation loss) and stops training if it doesn't improve\n",
        "# for a specified number of epochs ('patience'). This ensures we save the\n",
        "# model state from the epoch with the best generalization performance.\n",
        "#\n",
        "earlyStoppingCallback = EarlyStopping(\n",
        "                                       monitor              = 'val_loss', # The metric to watch\n",
        "                                       patience             = 3,          # Number of epochs with no improvement after which training will be stopped\n",
        "                                       restore_best_weights = True,       # Restore model weights from the epoch with the best 'val_loss'\n",
        "                                       verbose              = 1           # Log when stopping occurs\n",
        "                                     )\n"
      ],
      "metadata": {
        "id": "wN-iCul1nHWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(earlyStoppingCallback)"
      ],
      "metadata": {
        "id": "BVp4Sr1ArPeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Starting model training for {EPOCHS} epochs...\")\n",
        "print(\"===============================================\")\n",
        "\n",
        "#\n",
        "# Fit the model to the training data\n",
        "#\n",
        "# model.fit() executes the training process\n",
        "#\n",
        "# The input arguments are:\n",
        "# - X_train_processed : The preprocessed image data (features).\n",
        "# - y_train_encoded   : The one-hot encoded labels (targets).\n",
        "# - epochs            : The total number of iterations over the training set.\n",
        "# - batch_size        : The number of samples per gradient update.\n",
        "# - validation_data   : We explicitly pass our prepared testing data\n",
        "#                       (X_test_processed, y_test_encoded) to monitor\n",
        "#                       generalization.\n",
        "# - callbacks         : Monitors the 'val_loss' (validation loss) and stops\n",
        "#                       training if it doesn't improve\n",
        "# - verbose           : Sets the level of detail displayed during training (1 = progress bar).\n",
        "#\n",
        "# We include the new EarlyStopping callback here.\n",
        "# The 'epochs' parameter is set to 10, but the callback may stop it even sooner\n",
        "# if overfitting starts quickly\n",
        "#\n",
        "\n",
        "#\n",
        "# Train the CNN Model\n",
        "#\n",
        "# Note on validation_split: It is NOT used because we pass separate testing data\n",
        "# to the 'validation_data' parameter, which is the preferred method here.\n",
        "#\n",
        "trainingHistoryRegularised = cnnModelRegularised.fit(\n",
        "                                                      X_train_processed,\n",
        "                                                      y_train_encoded,\n",
        "                                                      epochs           = EPOCHS,                             # Set to 20. However, the EarlyStopping callback will decide the final number of epochs\n",
        "                                                      batch_size       = BATCH_SIZE,\n",
        "                                                      validation_data  = (X_test_processed, y_test_encoded), # Use test set for validation\n",
        "                                                      callbacks        = [earlyStoppingCallback],            # Add the EarlyStopping callback\n",
        "                                                      verbose          = 1                                   # Display training progress line-by-line\n",
        "                                                    )\n",
        "\n",
        "print(\"Model training complete!\")\n",
        "print(\"Training history is stored in the 'trainingHistoryRegularised' variable\")"
      ],
      "metadata": {
        "id": "EuLApx0trsHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Displaying a brief summary of the final training results\n",
        "#\n",
        "print(trainingHistoryRegularised.history)\n",
        "print(\"======================\")\n",
        "print(\"Final Training Summary\")\n",
        "print(\"======================\")\n",
        "print(f\"Final Training Loss       : {trainingHistoryRegularised.history['loss'][-1]:.4f}\"        )\n",
        "print(f\"Final Training Accuracy   : {trainingHistoryRegularised.history['accuracy'][-1]:.4f}\"    )\n",
        "print(f\"Final Validation Loss     : {trainingHistoryRegularised.history['val_loss'][-1]:.4f}\"    )\n",
        "print(f\"Final Validation Accuracy : {trainingHistoryRegularised.history['val_accuracy'][-1]:.4f}\")"
      ],
      "metadata": {
        "id": "l3Guy5wfrojL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observation on Model**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The final training summary for the **regularized model** is extremely positive, indicating a successful resolution to the initial overfitting problem and achieving **high performance** for the brain tumor classification task.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Metrics and Interpretation**\n",
        "\n",
        "- **Final Training Accuracy:** `0.9890` (98.90%)  \n",
        "  → Confirms the model has effectively mastered the training dataset.  \n",
        "\n",
        "- **Final Validation Accuracy:** `0.9710` (97.10%)  \n",
        "  → The most crucial metric. Accuracy this high on unseen data is **outstanding** for a medical classification task and shows strong reliability.  \n",
        "\n",
        "- **Final Training Loss:** `0.0364`  \n",
        "  → Very low, suggesting confident predictions on the training set.  \n",
        "\n",
        "- **Final Validation Loss:** `0.1315`  \n",
        "  → Higher than training loss but still very low in absolute terms, indicating good generalization.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion on Generalization**\n",
        "\n",
        "The primary observation is the successful achievement of **strong generalization with minimal overfitting**:\n",
        "\n",
        "- **High Absolute Accuracy:** Both training and validation accuracies are above **97%**.  \n",
        "- **Minimal Generalization Gap:** Training accuracy (98.90%) vs validation accuracy (97.10%) shows a gap of only **1.8 percentage points**.  \n",
        "- This confirms that **Dropout layers** and **Early Stopping** worked as intended, preventing overfitting and ensuring robust performance on new samples.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Final Note**\n",
        "This model is considered **production-ready** in terms of performance metrics.\n"
      ],
      "metadata": {
        "id": "qGDESQaj6H4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation and Visualization**"
      ],
      "metadata": {
        "id": "AbAGuvaW7Dmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Evaluate the model on the testing set\n",
        "#\n",
        "# This provides the final, unbiased performance metrics.\n",
        "#\n",
        "lossRegularised, accuracyRegularised = cnnModelRegularised.evaluate(\n",
        "                                                                     X_test_processed,\n",
        "                                                                     y_test_encoded,\n",
        "                                                                     verbose = 1\n",
        "                                                                   )\n",
        "\n",
        "print(\"Regularisex Model Evaluation\")\n",
        "print(\"============================\")\n",
        "print(f\"Test Loss    : {lossRegularised:.4f}\"    )\n",
        "print(f\"Test Accuracy: {accuracyRegularised:.4f}\")"
      ],
      "metadata": {
        "id": "KYsbQcQXBise"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Plot Model Comparison (Loss)\n",
        "#\n",
        "plt.figure(figsize = (15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(trainingHistoryInitial.history['loss'],         label = 'Initial Model Training Loss',     linestyle = '--', color = 'red' )\n",
        "plt.plot(trainingHistoryInitial.history['val_loss'],     label = 'Initial Model Validation Loss',                     color = 'red' )\n",
        "plt.plot(trainingHistoryRegularised.history['loss'],     label = 'Regularized Model Training Loss', linestyle = '--', color = 'blue')\n",
        "plt.plot(trainingHistoryRegularised.history['val_loss'], label = 'Regularized Model Validation Loss',                 color = 'blue')\n",
        "plt.title('Training vs. Validation Loss (Model Comparison)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "#\n",
        "# Plot Model Comparison (Accuracy)\n",
        "#\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(trainingHistoryInitial.history['accuracy'],         label = 'Initial Model Training Acc',     linestyle = '--', color = 'red' )\n",
        "plt.plot(trainingHistoryInitial.history['val_accuracy'],     label = 'Initial Model Validation Acc',                     color = 'red' )\n",
        "plt.plot(trainingHistoryRegularised.history['accuracy'],     label = 'Regularized Model Training Acc', linestyle = '--', color = 'blue')\n",
        "plt.plot(trainingHistoryRegularised.history['val_accuracy'], label = 'Regularized Model Validation Acc',                 color = 'blue')\n",
        "plt.title('Training vs. Validation Accuracy (Model Comparison)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s-M9ZFywCa7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observation on Model Performance**\n",
        "\n",
        "---\n",
        "\n",
        "### **Exceptional Performance and Generalization**\n",
        "\n",
        "The results of the final model evaluation are **outstanding** and confirm that the Convolutional Neural Network (CNN) is highly effective and reliable for the brain tumor classification task.\n",
        "\n",
        "* **Test Accuracy: 0.9718 (97.18%)**  \n",
        "    This is an extremely high score, indicating that the model correctly classifies the tumor type (or the absence of a tumor) in over **97 out of 100** independent test images. For a medical image analysis task, this level of accuracy is highly desirable.\n",
        "\n",
        "* **Test Loss: 0.1085**  \n",
        "    The loss value is remarkably low. A low categorical cross-entropy loss signifies that the model's predictions are not just correct, but are made with **very high confidence**. The predicted probabilities for the correct class are close to 1.0, while the probabilities for the incorrect classes are close to 0.0.\n",
        "\n",
        "### **Key Conclusion: Excellent Generalization**\n",
        "\n",
        "The most crucial observation is the confirmation of **excellent generalization**. The test set result of $97.18\\%$ demonstrates that:\n",
        "\n",
        "1.  **The model is robust.** It performs equally well on data it has never encountered before.\n",
        "2.  **There is no significant overfitting.** The model has successfully learned the core features of the tumor types rather than memorizing noise or specific artifacts from the training set.\n",
        "\n",
        "This model is performing at a high standard, indicating a successful conclusion to the modeling phase."
      ],
      "metadata": {
        "id": "paxXKEKVEcuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Plot Training History (Accuracy and Loss)\n",
        "#\n",
        "plt.figure(figsize = (12, 5))\n",
        "\n",
        "#\n",
        "# Plot Training and Validation Accuracy\n",
        "#\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(trainingHistoryRegularised.history['accuracy'],     label = 'Training Accuracy'  )\n",
        "plt.plot(trainingHistoryRegularised.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "#\n",
        "# Plot Training and Validation Loss\n",
        "#\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(trainingHistoryRegularised.history['loss'],     label = 'Training Loss'  )\n",
        "plt.plot(trainingHistoryRegularised.history['val_loss'], label = 'Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UTCwkR9pC_pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Training History (Accuracy and Loss)\n",
        "\n",
        "---\n",
        "\n",
        "### **Accuracy Over Epochs (Left Plot)**\n",
        "\n",
        "The accuracy plot shows the model's performance on both the training and validation datasets across 10 epochs.\n",
        "\n",
        "* **Rapid Initial Learning:** The model exhibits **rapid learning** in the first 3-4 epochs, with both training and validation accuracy increasing sharply from around $0.70$ to over $0.90$. This indicates that the Convolutional Neural Network (CNN) is highly effective at extracting relevant features from the Brain MRI images.\n",
        "\n",
        "* **High Saturation Point:** Both accuracies stabilize at a very high level, with the **Training Accuracy** reaching nearly $1.00$ (or $100\\%$) and the **Validation Accuracy** peaking around $0.98$. Achieving $\\sim 98\\%$ on unseen validation data is an excellent result for this task.\n",
        "\n",
        "* **Minor Overfitting/Variance:** After **Epoch 6**, the curves begin to diverge slightly. The training accuracy remains extremely high and flat, while the validation accuracy shows **more variance** (a slight drop followed by a rise in Epochs 8 and 9). This divergence suggests **minor overfitting** beginning in the later epochs. The model is still improving its fit to the training data without necessarily improving its generalization ability further on the validation set.\n",
        "\n",
        "### **Loss Over Epochs (Right Plot)**\n",
        "\n",
        "The loss plot, specifically using *categorical cross-entropy*, tracks how close the model's predictions are to the true labels.\n",
        "\n",
        "* **Consistent Decrease:** Both the **Training Loss** and **Validation Loss** decrease quickly and consistently up to **Epoch 6**. This perfectly mirrors the rapid increase in accuracy, confirming that the model is converging well.\n",
        "\n",
        "* **Optimal Point and Rebound:** The **Validation Loss** reaches its minimum point around **Epoch 6** (a value just above $0.10$). Crucially, after this point (Epochs 7, 8, and 9), the Validation Loss begins to **increase and becomes volatile** while the Training Loss continues its slow decline.\n",
        "\n",
        "* **Clear Sign of Overfitting:** The increasing validation loss coupled with flat or continuing decreasing training loss is the **textbook sign of overfitting**. After Epoch 6, the model is likely learning noise or highly specific features unique to the training set, which harms its performance on the generalization set.\n",
        "\n",
        "### **Overall Recommendation**\n",
        "\n",
        "Based on the combined plots:\n",
        "\n",
        "1.  **Stop Training Early:** The **ideal stopping point** for this model appears to be **Epoch 6 or 7**, where the validation loss is at its minimum and validation accuracy is near its peak.\n",
        "2.  **Excellent Model:** Despite the minor overfitting after Epoch 6, the overall training process was highly successful, resulting in a model with a **peak validation accuracy of approximately $98\\%$**."
      ],
      "metadata": {
        "id": "wahlGaCTHT0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Prediction**"
      ],
      "metadata": {
        "id": "TFsne_OAHvrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Make predictions\n",
        "#\n",
        "y_PredictedProbalities = cnnModelRegularised.predict(X_test_processed)\n",
        "\n",
        "#\n",
        "# Convert probabilities to class indices (0, 1, 2, 3)\n",
        "# argmax returns the index of the highest probability\n",
        "#\n",
        "# y_PredictedClasses = [np.argmax(element) for element in y_PredictedProbalities]\n",
        "y_PredictedClasses = np.argmax(y_PredictedProbalities, axis = 1)\n",
        "\n",
        "#\n",
        "# Get true class indices from the one-hot encoded array\n",
        "#\n",
        "y_TrueClasses = np.argmax(y_test_encoded, axis = 1)\n",
        "\n",
        "print(\"Shape of Predicted Classes :\", y_PredictedClasses.shape)\n",
        "print(\"Shape of True Classes      :\", y_TrueClasses.shape)"
      ],
      "metadata": {
        "id": "0Cj23aBOHzsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_TrueClasses[:5]"
      ],
      "metadata": {
        "id": "FBPVugRdJuPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_PredictedClasses[:5]"
      ],
      "metadata": {
        "id": "NpbgMArUJ0EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation Metrics**"
      ],
      "metadata": {
        "id": "d042Qk-0SahN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Error Analysis : Displaying Misclassified Images**\n",
        "This section identifies all instances where the model's prediction does not match the true label and plots the first few examples."
      ],
      "metadata": {
        "id": "MLZe8kyWK_Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Identify Incorrect Predictions\n",
        "#\n",
        "# We use boolean indexing to find where the predicted classes\n",
        "# are NOT EQUAL to the true classes. The result is a boolean array.\n",
        "#\n",
        "FIRST_N_MISMATCH = 10\n",
        "incorrectIndices = np.where(y_PredictedClasses != y_TrueClasses)[0]\n",
        "print(f\"Total misclassified images found: {len(incorrectIndices)}\")\n",
        "\n",
        "#\n",
        "# Select a subset of the first n incorrect indices to plot\n",
        "#\n",
        "# We limit this to prevent the output from becoming too long\n",
        "#\n",
        "plotIndices   = incorrectIndices[:FIRST_N_MISMATCH]\n",
        "numberOfPlots = len(plotIndices)\n",
        "\n",
        "if numberOfPlots > 0:\n",
        "  #\n",
        "  # Create a figure to display the misclassified images\n",
        "  #\n",
        "  plt.figure(figsize = (16, 4 * ((numberOfPlots + 3) // 4))) # Dynamic sizing\n",
        "  plt.suptitle(f\"First {numberOfPlots} Misclassified Images\", fontsize = 18, fontweight = 'bold')\n",
        "  plt.tight_layout(pad = 3.0, rect = [0, 0.03, 1, 0.95])     # Adjust overall padding\n",
        "\n",
        "  #\n",
        "  # Loop through the selected incorrect indices and plot the data\n",
        "  #\n",
        "  for i, index in enumerate(plotIndices):\n",
        "    #\n",
        "    # Retrieve the necessary data for the misclassified image\n",
        "    # X_test holds the original PIL image data needed for visualization\n",
        "    #\n",
        "    originalImage  = X_test[index]\n",
        "    trueLabel      = CATEGORIES[y_TrueClasses[index]]\n",
        "    predictedLabel = CATEGORIES[y_PredictedClasses[index]]\n",
        "\n",
        "    ax = plt.subplot((numberOfPlots + 3) // 4, 4, i + 1)\n",
        "    ax.imshow(originalImage, cmap = 'gray') # Display the original raw image\n",
        "\n",
        "    #\n",
        "    # Set the title to clearly show the error\n",
        "    #\n",
        "    titleText = f\"True: {trueLabel}\\nPredicted: {predictedLabel}\"\n",
        "\n",
        "    #\n",
        "    # Change the text color to red to highlight the error\n",
        "    #\n",
        "    ax.set_title(titleText, fontsize = 10, color = 'red', fontweight = 'bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # plt.show() # Commented out to avoid display issues\n",
        "else:\n",
        "  print(\"No misclassified images to display (This is unlikely with real data)\")"
      ],
      "metadata": {
        "id": "cTwyW7RILD_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classification Report**"
      ],
      "metadata": {
        "id": "pwFJwY-1N2pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Generate the Classification Report\n",
        "#\n",
        "print(\"=\"*55)\n",
        "print(\"Classification Report\")\n",
        "print(\"=\"*55)\n",
        "print(classification_report(y_TrueClasses, y_PredictedClasses, target_names = CATEGORIES))\n",
        "print(\"=\"*55)"
      ],
      "metadata": {
        "id": "fCKnJdPeN6t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Confusion Matrix**"
      ],
      "metadata": {
        "id": "07qRNfetOY-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Generate the Confusion Matrix\n",
        "#\n",
        "confusionMatrix = confusion_matrix(y_TrueClasses, y_PredictedClasses)\n",
        "\n",
        "#\n",
        "# Plot the Confusion Matrix using a heatmap for better visualization\n",
        "#\n",
        "plt.figure(figsize = (10, 8))\n",
        "\n",
        "sns.heatmap(\n",
        "             confusionMatrix,\n",
        "             annot       = True,\n",
        "             fmt         = 'd',\n",
        "             cmap        = 'coolwarm',\n",
        "             linewidths  = .5,\n",
        "             xticklabels = CATEGORIES,\n",
        "             yticklabels = CATEGORIES\n",
        "           )\n",
        "plt.title('Confusion Matrix', fontsize = 16)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.show() # Comment out if there are any display issues"
      ],
      "metadata": {
        "id": "P0PY0aunOcDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observation Confusion Matrix**\n",
        "\n",
        "The confusion matrix provides a detailed breakdown of the model's performance on the test set for the four classes: **glioma, meningioma, notumor, and pituitary**.  \n",
        "\n",
        "- **Rows = True Labels (actual classes)**  \n",
        "- **Columns = Predicted Labels (model's predictions)**  \n",
        "\n",
        "---\n",
        "\n",
        "### **Exceptional Performance on Healthy and Pituitary Cases**\n",
        "\n",
        "The model demonstrates **near-perfect accuracy** in two key areas:\n",
        "\n",
        "- **Notumor (404 / 405)**  \n",
        "  - 404 correctly classified  \n",
        "  - 1 misclassified (as meningioma)  \n",
        "  - Extremely reliable at identifying a healthy brain  \n",
        "\n",
        "- **Pituitary (299 / 300)**  \n",
        "  - 299 correctly classified  \n",
        "  - 1 misclassified (as meningioma)  \n",
        "  - Very strong identification of pituitary tumors  \n",
        "\n",
        "These high True Positive rates suggest that the features for **Notumor** and **Pituitary** are highly distinct and easily learned by the CNN.\n",
        "\n",
        "---\n",
        "\n",
        "### **Primary Area of Confusion: Meningioma vs. Glioma**\n",
        "\n",
        "Most classification errors occur between the **glioma** and **meningioma** classes:\n",
        "\n",
        "- **Meningioma → Glioma (20 cases)**  \n",
        "  - Largest single error type  \n",
        "  - Indicates difficulty distinguishing meningioma from glioma features  \n",
        "\n",
        "- **Glioma → Meningioma (6 cases)**  \n",
        "  - Fewer misclassifications compared to the reverse direction  \n",
        "\n",
        "- **Total Meningioma Misclassifications = 28**  \n",
        "  - 20 misclassified as glioma  \n",
        "  - 3 misclassified as notumor  \n",
        "  - 5 misclassified as pituitary  \n",
        "  - The fact that **20 out of 28 errors** are meningioma → glioma highlights the critical weakness.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion and Key Takeaway**\n",
        "The overall classifier is highly accurate, with an excellent ability to rule out tumors (**notumor class performance**) and identify **pituitary tumors.** The performance of the model would be significantly improved by addressing the specific feature overlap causing the confusion between meningioma and glioma.\n",
        "\n",
        "- The classifier is **highly accurate overall**  \n",
        "- Excellent ability to rule out tumors (**Notumor class**)  \n",
        "- Outstanding identification of **Pituitary tumors**  \n",
        "- **Main challenge:** Overlap between **Meningioma** and **Glioma** features  \n",
        "\n",
        "**Improvement Opportunity:** Focus on better feature extraction or domain-specific augmentation to reduce confusion between **meningioma** and **glioma**\n"
      ],
      "metadata": {
        "id": "wpWyf_fKRFM9"
      }
    }
  ]
}