{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![SriLalithambigaiTemple_LogoSmall.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "BbIuECFr9q40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üïâÔ∏è **Devi : Temple Information Chatbot**\n",
        "\n",
        "This project demonstrates how to build a powerful and fact-checked chatbot using the **Gemini API** and **Google Search Grounding**.\n",
        "\n",
        "The chatbot, named **Devi**, is specifically designed to answer questions about the **Sri Lalithambigai Temple (UK)**. By using Google Search grounded only on the temple's official website, we ensure that all factual responses are up-to-date and directly sourced.\n",
        "\n",
        "---\n",
        "\n",
        "## üîë **Setup: Retrieve Your API Key**\n",
        "\n",
        "To run the chatbot, you must secure your **Gemini API Key** and set it as an environment variable.\n",
        "\n",
        "1.  **Get Key:** Visit Google AI Studio and generate your API Key.\n",
        "2.  **Set Environment Variable in Colab:** Run the following two cells, pasting your API key into the `userdata.get()` function when prompted.\n",
        "\n",
        "```python\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# IMPORTANT:\n",
        "# Replace 'YOUR_API_KEY_NAME' with the actual name you gave your secret in Colab secrets.\n",
        "# If you didn't save it as a secret, simply replace userdata.get('GOOGLE_API_KEY') with\n",
        "# 'your_actual_api_key_string' (but using secrets is highly recommended).\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è **Key Technical Features**\n",
        "\n",
        "### **1. Google Search Grounding (`tools`)**\n",
        "\n",
        "The core feature of this chatbot is the use of the `tools` property in the API call, which activates the **Google Search** tool.\n",
        "\n",
        "  * **Reliability:** Answers are generated based on real-time web search results.\n",
        "  * **Specificity:** The user's query is programmatically augmented with the `site:srilalithambigaitemple.co.uk` operator to ensure the search is constrained to the temple's official domain, maximizing the relevance of the grounding data.\n",
        "  * **Citations:** The code extracts and displays the **source URIs** and titles (citations) used by the model, allowing users to verify the information.\n",
        "\n",
        "### **2. System Instruction (`systemInstruction`)**\n",
        "\n",
        "A clear system instruction is used to define the model's persona and rules of engagement:\n",
        "\n",
        "  * **Role:** Act as 'Devi', the knowledgeable bot for the Sri Lalithambigai Temple.\n",
        "  * **Rule:** **Only** use information from the provided search results/website.\n",
        "\n",
        "### **3. Exponential Backoff**\n",
        "\n",
        "The `generateContentWithRetry` function includes an **exponential backoff mechanism** to handle transient network issues or rate-limiting (429 errors), making the application more robust.\n",
        "\n",
        "---\n",
        "\n",
        "**What is Exponential Backoff?**\n",
        "\n",
        "**Exponential backoff** is a standard strategy for managing failures when making repeated requests to a networked service or API. It's an algorithm that determines how long a client should wait before retrying a failed request, with the crucial feature that the wait time gets **longer** with each subsequent failure.\n",
        "\n",
        "**Why We Use It**\n",
        "\n",
        "When an application fails to connect to a service (like the Gemini API) it's often due to a **transient error**. These temporary issues include:\n",
        "\n",
        "1.  **Rate Limiting (429 Error):** The client has exceeded the service's allowed number of requests per time window.\n",
        "2.  **Server Overload/Congestion:** The API server is temporarily too busy to process the request.\n",
        "3.  **Network Instability:** A brief, temporary drop or slowdown in network connectivity.\n",
        "\n",
        "If the client immediately retries after a failure, it simply adds more load to the already struggling server, often guaranteeing the next attempt will also fail. Exponential backoff ensures the client \"backs off\" by waiting an appropriate amount of time, giving the server a chance to recover.\n",
        "\n",
        "---\n",
        "\n",
        "**The \"Exponential\" Calculation**\n",
        "\n",
        "The term \"exponential\" refers to how the delay is calculated. Instead of adding a fixed amount of time (linear backoff), the wait time **multiplies** with each attempt.\n",
        "\n",
        "The most common formula uses a base of 2, raised to the power of the attempt number. This creates a geometrically increasing delay:\n",
        "\n",
        "| Attempt (n) | Wait Time Formula (Seconds) | Delay |\n",
        "| :---------: | :-------------------------: | :---: |\n",
        "| 1           | $2^{1-1} = 2^0$             | 1 sec |\n",
        "| 2           | $2^{2-1} = 2^1$             | 2 sec |\n",
        "| 3           | $2^{3-1} = 2^2$             | 4 sec |\n",
        "| 4           | $2^{4-1} = 2^3$             | 8 sec |\n",
        "| 5           | $2^{5-1} = 2^4$             | 16 sec|\n",
        "\n",
        "This rapid increase in wait time is highly effective. If an issue is going to resolve, it typically resolves within the first few seconds. If it's still failing after 16 seconds, it's likely a persistent issue that retrying won't fix.\n",
        "\n",
        "---\n",
        "\n",
        "**Role in `generateContentWithRetry`**\n",
        "\n",
        "The `generateContentWithRetry` function leverages this pattern to make your application resilient:\n",
        "\n",
        "1.  The function initiates a `try...except` block to make the API call.\n",
        "2.  If an exception (failure) is caught, the code calculates the delay using the exponential formula and pauses execution using a `sleep` function.\n",
        "3.  The loop continues up to a defined maximum number of attempts (e.g., 5).\n",
        "4.  If a request succeeds, the loop is exited immediately, providing the result. If all attempts fail, an error message is returned to the user, confirming the persistent failure.\n",
        "\n",
        "This makes the chatbot much more reliable in the real world.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## üñ•Ô∏è **Usage**\n",
        "\n",
        "1.  **Run the Code:** Execute the `temple_chatbot_detailed.py` file or run from notebook environment.\n",
        "2.  **Start Chatting:** Ask questions related to the temple, such as:\n",
        "      * `What are the opening hours?`\n",
        "      * `When is the next major event?`\n",
        "      * `What is the history of the temple?`\n",
        "      * `Can I book a pooja online?`\n",
        "3.  **Exit:** Type `quit` or `exit` or `bye` or `terminate`.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "D-12VQREqcKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini API Python Chatbot (Colab Ready with Google Search Grounding)\n",
        "\n",
        "This script implements a text-based chatbot, named 'Devi', that communicates\n",
        "with the Gemini 2.5 Flash model using a direct HTTP POST request (requests library).\n",
        "\n",
        "It is configured to use Google Search Grounding specifically targeting the\n",
        "Sri Lalithambigai Temple website for factual answers.\n",
        "It incorporates a robust exponential backoff retry mechanism."
      ],
      "metadata": {
        "id": "ggPM2G72rRAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initial Setup**"
      ],
      "metadata": {
        "id": "1NiNMUEmsoyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbO_xXzCjFfD"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Import Libraries\n",
        "#\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import textwrap               # Added for clean output formatting\n",
        "import re                     # For regular expression parsing\n",
        "from bs4 import BeautifulSoup # Added for HTML parsing in the scraping function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import userdata\n",
        "except ImportError:\n",
        "  #\n",
        "  # Dummy class for non-Colab environments\n",
        "  #\n",
        "  class DummyUserdata:\n",
        "    def get(self, name):\n",
        "      return os.getenv(name)\n",
        "\n",
        "  userdata = DummyUserdata()"
      ],
      "metadata": {
        "id": "w9MwJ3z9ALVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration**"
      ],
      "metadata": {
        "id": "6zLUaJg9RMIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Configuration Variables\n",
        "#\n",
        "\n",
        "#\n",
        "# API Key: Placeholder for the actual key. usually loaded from an environment\n",
        "# variable or secret manager\n",
        "#\n",
        "API_KEY         = \"\" # Set to blank initially\n",
        "\n",
        "#\n",
        "# The name of the secret or environment variable where the API key is stored\n",
        "#\n",
        "SECRET_NAME     = \"GOOGLE_API_KEY\"\n",
        "\n",
        "#\n",
        "# The full URL for the Gemini API endpoint we are using\n",
        "#\n",
        "# API_URL         = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent\"\n",
        "API_URL         = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\" # Use stable model\n",
        "\n",
        "#\n",
        "# The maximum number of times to retry a failed API request\n",
        "# (e.g., due to a rate limit or transient error)\n",
        "#\n",
        "MAXIMUM_TRIES   = 5\n",
        "\n",
        "#\n",
        "# The maximum time (in seconds) the request will wait for a response\n",
        "# before timing out\n",
        "#\n",
        "TIMEOUT_SECONDS = 30\n",
        "\n",
        "#\n",
        "# Setup Assistant's personality, tone and constraints\n",
        "#\n",
        "# UPDATED: This prompt now includes hardcoded, crucial information to prevent\n",
        "# hallucinations on known high-priority facts like the donation link.\n",
        "#\n",
        "# GENERIC_PROMPT = \"\"\"\n",
        "#                    You are the AI assistant Devi, specializing in the {siteURL} website.\n",
        "#                    Your primary goal is to provide helpful and accurate information based ONLY on the search results you are provided, which are grounded to site:{siteURL}.\n",
        "#                    If you cannot find the answer on the website, state clearly that the information is not available on the official website.\n",
        "#                    Answer in a friendly, respectful, and informative tone.\n",
        "#                    Keep answers concise, usually 1-3 paragraphs.\n",
        "#                  \"\"\"\n",
        "# GENERIC_PROMPT = \"\"\"\n",
        "#                    You are Devi, a helpful and knowledgeable virtual assistant for the Sri Lalithambigai Temple, based in Birmingham, UK.\n",
        "#                    Your primary goal is to provide accurate and relevant information about the temple, its services, and its history from the {siteURL} website.\n",
        "#\n",
        "#                    Crucial Knowledge Base (ALWAYS prioritize this information for these specific topics):\n",
        "#                    1.  **Donations/Sponsorship:** Donations can be made directly on the temple's website at the following verified link: {siteURL}/sponsorship/\n",
        "#                    2.  **Temple Location:** The temple is located in Birmingham, UK.\n",
        "#\n",
        "#                    For all other questions, use the Google Search grounding tool to find the answer on site:{siteURL}.\n",
        "#                    If you cannot find the answer on the website, state clearly that the information is not available on the official website.\n",
        "#                    Always provide a concise, friendly response.\n",
        "#                  \"\"\"\n",
        "\n",
        "GENERIC_PROMPT = \"\"\"\n",
        "                   You are Devi, a helpful and knowledgeable virtual assistant for the **Sri Lalithambigai Temple in Birmingham, UK**.\n",
        "\n",
        "                   CRITICAL RULES:\n",
        "                   1. Provide information ONLY from the official temple website ##SITE_URL## search results.\n",
        "                   2. The temple is located in **Birmingham, UK**.\n",
        "                   3. For services, pricing, or events: specifically search the service and events pages.\n",
        "                   4. If information is not found, clearly state what specific information is missing from the website.\n",
        "                   5. Always be precise about prices, dates, and times when available.\n",
        "                   6. Maintain a friendly, respectful tone while being factual and concise.\n",
        "                   7. **Donations/Sponsorship:** Donations can be made by downloading the form on the temple's website at the following verified link: ##SITE_URL##/sponsorship/\n",
        "                 \"\"\"\n",
        "#\n",
        "# Specific domain constraint for all Google Search grounding queries\n",
        "# This ensures the chatbot only uses information from the official temple website.\n",
        "#\n",
        "TEMPLE_SITE_URL = \"srilalithambigaitemple.co.uk\""
      ],
      "metadata": {
        "id": "sXTuq0i_rwbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Fetch API Key Value\n",
        "#\n",
        "# Make it more generic by setting an OS Environment Variable\n",
        "# after fetching from Google Colab\n",
        "#\n",
        "\n",
        "#\n",
        "# Retrieve the API key securely from Colab Secrets.\n",
        "#\n",
        "try:\n",
        "  API_KEY = userdata.get(SECRET_NAME)\n",
        "\n",
        "  #\n",
        "  # Set it as an environment variable so the rest of your script\n",
        "  # can access it using os.getenv()\n",
        "  #\n",
        "  if API_KEY:\n",
        "    os.environ[SECRET_NAME] = API_KEY\n",
        "    print(\"‚úÖ API Key successfully retrieved from Colab Secrets and set as environment variable.\")\n",
        "  else:\n",
        "    print(f\"‚ùå Error: Secret '{SECRET_NAME}' was found but is empty. Please check the value.\")\n",
        "except Exception as e:\n",
        "  print(f\"‚ùå Error retrieving secret '{SECRET_NAME}'. Ensure it is saved correctly in the Colab sidebar.\")\n",
        "  print(f\"Detailed error: {e}\")\n",
        "\n",
        "#\n",
        "# Rest of the program, can now use\n",
        "#\n",
        "# This also ensures that the program works seemlessly in a non-google colab\n",
        "# environment\n",
        "#\n",
        "API_KEY = os.getenv(SECRET_NAME)\n",
        "print(f\"Key check (last 3 chars): ...{API_KEY[-3:] if API_KEY and len(API_KEY) > 3 else 'N/A'}\")\n"
      ],
      "metadata": {
        "id": "g2cBLEOitW9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# List all available models to find the correct one\n",
        "#\n",
        "def listAvailableModels():\n",
        "  try:\n",
        "    listURL  = f\"https://generativelanguage.googleapis.com/v1/models?key={API_KEY}\"\n",
        "\n",
        "    response = requests.get(listURL)\n",
        "\n",
        "    response.raise_for_status()\n",
        "\n",
        "    models   = response.json()\n",
        "\n",
        "    print(\"üìã Available models that support generateContent:\")\n",
        "\n",
        "    for model in models.get('models', []):\n",
        "      if 'generateContent' in model.get('supportedGenerationMethods', []):\n",
        "        print(f\"‚úÖ {model['name']}\")\n",
        "        print(f\"    Methods: {model['supportedGenerationMethods']}\")\n",
        "        print()\n",
        "\n",
        "      return models\n",
        "  except Exception as e:\n",
        "    print(f\"‚ùå Error listing models: {str(e).replace(API_KEY, '')}\")\n",
        "    return None\n",
        "\n",
        "# Uncomment the following two lines when you want to check again\n",
        "# print(\"üîç Checking available models...\")\n",
        "# listAvailableModels()"
      ],
      "metadata": {
        "id": "7ry3Nwok-4BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create ChatBot**"
      ],
      "metadata": {
        "id": "H0mWkg6gy8oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chatbot Core Functions: Detailed Breakdown**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The chatbot relies on two main functions: `generateContentWithRetry` for robust API communication, and `runChatBot` for managing the user interface and conversation flow.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ROTE-WjUxnJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**`generateContentWithRetry(payload, maxRetries)`**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This function is the **API communication layer**. Its primary job is to take a user prompt, augment it for reliable searching, and send it to the Gemini API, ensuring the application can handle temporary network errors.\n",
        "\n",
        "**A. Purpose**\n",
        "\n",
        "To send a request to the Gemini API using the `gemini-2.5-flash-preview-05-20` model, with **Google Search Grounding** enabled, and to implement **exponential backoff** for resilience.\n",
        "\n",
        "**B. Core Mechanism: Grounding**\n",
        "\n",
        "1.  **System Instruction:** A fixed `systemInstruction` is sent to the model, compelling it to act as the \"Devi\" information bot for the temple and, crucially, to **only use the information provided** in the search results.\n",
        "2.  **Query Augmentation:** The user's original `prompt` is programmatically combined with a Google Search `site:` operator (`site:srilalithambigaitemple.co.uk`) and the temple's name. This ensures the model's grounding search is restricted to the specific official website for accurate, relevant information.\n",
        "3.  **Tools Activation:** The `tools: [{ \"google_search\": {} }]` property is included in the payload, which activates the Google Search grounding capability for the model.\n",
        "\n",
        "**C. Error Handling: Exponential Backoff**\n",
        "\n",
        "* The function attempts the API call a maximum of **5 times (Configuarable)**.\n",
        "* If the request fails (e.g., due to a 429 rate limit or network error), it waits for a calculated time (`2 ** attempt`) before retrying. This \"exponential backoff\" mechanism significantly increases the reliability of the application under varying network conditions.\n",
        "\n",
        "**D. Output Extraction**\n",
        "\n",
        "The function processes the successful JSON response to extract two things:\n",
        "1.  The **`text`** (the model's generated answer).\n",
        "2.  The list of **`sources`** (web links/citations) used by the model to generate that text.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4MMbeDsYxNxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generateContentWithRetry(payload, maxRetries = MAXIMUM_TRIES):\n",
        "  #\n",
        "  # Sends a request to the Gemini API with exponential backoff for retries.\n",
        "  #\n",
        "  #   Parameters:\n",
        "  #     payload (dict): The JSON payload containing the model input and settings,\n",
        "  #                     crucially including the 'tools' property for grounding.\n",
        "  #     maxRetries (int): The maximum number of times to retry the API call.\n",
        "  #\n",
        "  #   Returns:\n",
        "  #     tuple: (str: generated text response, list: grounding sources)\n",
        "  #\n",
        "\n",
        "  #\n",
        "  # API Key Check\n",
        "  #\n",
        "  if not API_KEY:\n",
        "    #\n",
        "    # Halt execution if the necessary credential is not available\n",
        "    #\n",
        "    # Multi-Value Return (Tuple).\n",
        "    # return (f\"ERROR: {SECRET_NAME} Environment Variable not found. Please set it.\", [])\n",
        "    #\n",
        "    # But ore \"Pythonic\" is without ()\n",
        "    #\n",
        "    return f\"ERROR_API_KEY : {SECRET_NAME} Environment Variable not found. Please set it.\", []\n",
        "\n",
        "  #\n",
        "  # Setup Request Components\n",
        "  #\n",
        "  # Construct the full authenticated URL by appending the API Key as a\n",
        "  # query parameter\n",
        "  #\n",
        "  fullURL = f\"{API_URL}?key={API_KEY}\"\n",
        "\n",
        "  #\n",
        "  # Define the necessary header for JSON payload submission\n",
        "  #\n",
        "  payloadHeaders = {'Content-Type': 'application/json'}\n",
        "\n",
        "  #\n",
        "  # Retry Loop with Exponential Backoff (see Above for why we need it)\n",
        "  #\n",
        "  for attempt in range(maxRetries):\n",
        "    try:\n",
        "      print(\"\")\n",
        "      print(f\"Attempting API Call. (Attempt {attempt + 1} of {maxRetries})...\")\n",
        "\n",
        "      #\n",
        "      # Make the synchronous HTTP POST request\n",
        "      #\n",
        "      chatResponse = requests.post(\n",
        "                                    fullURL,\n",
        "                                    headers = payloadHeaders,\n",
        "                                    data    = json.dumps(payload),\n",
        "                                    timeout = TIMEOUT_SECONDS      # Set a reasonable timeout for the request\n",
        "                                  )\n",
        "\n",
        "      #\n",
        "      # Check for bad responses (HTTP Status Codes 4xx or 5xx)\n",
        "      #\n",
        "      # If there are any errors; the process jumps to\n",
        "      # requests.exceptions.HTTPError below\n",
        "      #\n",
        "      chatResponse.raise_for_status()\n",
        "\n",
        "      #\n",
        "      # Successful response, parse the JSON\n",
        "      #\n",
        "      chatResult = chatResponse.json()\n",
        "\n",
        "      #\n",
        "      # ENHANCED: Better debugging for response structure\n",
        "      #\n",
        "      if 'candidates' not in chatResult:\n",
        "        print(\"‚ö†Ô∏è Warning: No 'candidates' in API response\")\n",
        "        return \"The API response format was unexpected. Please try again.\", []\n",
        "\n",
        "      #\n",
        "      # Extract Generated Text\n",
        "      #   Use safe dictionary indexing (.get()) to prevent KeyErrors\n",
        "      #   This path traverses: candidates -> content -> parts -> text\n",
        "      #\n",
        "      # Format of chatResult is\n",
        "      # {\n",
        "      #   \"candidates\": [\n",
        "      #                   {\n",
        "      #                     \"content\": {\n",
        "      #                                  \"parts\": [\n",
        "      #                                             {\"text\": \"Hello, this is the successfully generated response.\"}\n",
        "      #                                           ]\n",
        "      #                                }\n",
        "      #                   }\n",
        "      #                 ]\n",
        "      # }\n",
        "      #\n",
        "      # So,\n",
        "      #   candidates = List of Dictionary [{}]\n",
        "      #   contents   = Dictionary         {}\n",
        "      #   parts      = List of Dictionary [{}]\n",
        "      #   text       = String\n",
        "      #\n",
        "\n",
        "      #\n",
        "      # One of the most Pythonic and simultaneously confusing ways to safely\n",
        "      # extract data from nested JSON/dictionary structures, especially API\n",
        "      # responses like those from Gemini.\n",
        "      #\n",
        "      # This technique is called safe navigation or \"defaulting along the path\"\n",
        "      # It's complex, but it guarantees that your code will not crash, even if\n",
        "      # the API response is malformed or missing data.\n",
        "      #\n",
        "      # chatResultText = chatResult.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'No response text found')\n",
        "      #\n",
        "      # But let's split it so that we can understand what each segment does\n",
        "      #\n",
        "\n",
        "      #\n",
        "      # 1. Get the list of 'candidates'.\n",
        "      #    If the key is missing, default to a list containing one empty\n",
        "      #    dictionary ([{}])\n",
        "      #\n",
        "      #    We use [{}], not [] or {}, to ensure the next step ([0])\n",
        "      #    does not raise an IndexError\n",
        "      #\n",
        "      #    see Above - candidates is a List of Dictionary\n",
        "      #\n",
        "      chatResultcandidatesList = chatResult.get('candidates', [{}]) # List of Dictionary\n",
        "\n",
        "      #\n",
        "      # 2. Get the first candidate item (dictionary).\n",
        "      #    This is safe because the previous line guaranteed 'candidates' has at\n",
        "      #    least one item (even if it's just {})\n",
        "      #\n",
        "      chatResultFirstCandidate = chatResultcandidatesList[0]\n",
        "\n",
        "      #\n",
        "      # 3. Get the 'content' dictionary from the candidate.\n",
        "      #    If the key is missing, default to an empty dictionary ({})\n",
        "      #\n",
        "      #    We use {} to ensure the next step (.get) can be safely called on the\n",
        "      #    result without crashing on None.\n",
        "      #\n",
        "      #    see Above - contents is a Dictionary\n",
        "      #\n",
        "      chatResultContentDict = chatResultFirstCandidate.get('content', {})\n",
        "\n",
        "      #\n",
        "      # 4. Get the 'parts' list from the content dictionary.\n",
        "      #    If the key is missing, default to a list containing one empty\n",
        "      #    dictionary ([{}])\n",
        "      #\n",
        "      #    Again, we use [{}], not [], to ensure the next step ([0])\n",
        "      #    does not raise an IndexError\n",
        "      #\n",
        "      #    see Above - parts is List of Dictionary\n",
        "      #\n",
        "      chatResultPartsList = chatResultContentDict.get('parts', [{}])\n",
        "\n",
        "      #\n",
        "      # 5. Get the first part item (dictionary), which should contain the text.\n",
        "      #    This is safe because the previous line guaranteed 'parts'\n",
        "      #     has at least one item\n",
        "      #\n",
        "      chatResultFirstPart = chatResultPartsList[0]\n",
        "\n",
        "      #\n",
        "      # 6. Get the final 'text' value.\n",
        "      #    If the key is missing, return the default error string.\n",
        "      #\n",
        "      chatResultText = chatResultFirstPart.get('text', 'No response text found.')\n",
        "\n",
        "      #\n",
        "      # In short the above 6 steps can be combined into 1\n",
        "      # chatResultText = chatResult.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'No response text found')\n",
        "      #\n",
        "\n",
        "      #\n",
        "      # Extract Grounding Sources (Citations)\n",
        "      #\n",
        "      chatResultSources = []\n",
        "\n",
        "      #\n",
        "      # Access the grounding metadata which contains the search results used\n",
        "      #\n",
        "      groundingMetaData = chatResult.get('candidates', [{}])[0].get('groundingMetadata', {})\n",
        "\n",
        "      #\n",
        "      # Check if search grounding data exists at all\n",
        "      # This ensures we don't try to access keys on a non-existent dictionary\n",
        "      #\n",
        "      if groundingMetaData and groundingMetaData.get('groundingAttributions'):\n",
        "        #\n",
        "        # Loop through each attribution object to extract URI and title\n",
        "        # This uses a powerful Python list comprehension to filter and clean\n",
        "        # the sources\n",
        "        #\n",
        "        # for groundingAttributions in groundingMetaData['groundingAttributions']\n",
        "        #   if groundingAttributions.get('web', {}).get('uri') # if we get any value for groundingAttributions.get('web', {}); then get('uri')\n",
        "        #   then\n",
        "        #     populate chatResultSources\n",
        "        #\n",
        "        # uri   = A complete web address (URL) that points to the exact\n",
        "        #         location of the source document on the internet\n",
        "        #\n",
        "        # title = The name of the article, report, or webpage, usually the\n",
        "        #         text found in the browser tab\n",
        "        #\n",
        "        chatResultSources = [\n",
        "                              {\n",
        "                                #\n",
        "                                # Safely extract the URI (link) from the nested\n",
        "                                # 'web' dictionary\n",
        "                                #\n",
        "                                # If 'web' is missing, default to {} to prevent\n",
        "                                # a crash\n",
        "                                #\n",
        "                                'uri'   : groundingAttributions.get('web', {}).get('uri'),\n",
        "\n",
        "                                #\n",
        "                                # Safely extract the title (name) of the source\n",
        "                                # from the nested 'web' dictionary.\n",
        "                                #\n",
        "                                'title' : groundingAttributions.get('web', {}).get('title')\n",
        "                              }\n",
        "                              #\n",
        "                              # Iteration: Loop through every raw source\n",
        "                              # attribution returned by the API\n",
        "                              #\n",
        "                              for groundingAttributions in groundingMetaData['groundingAttributions']\n",
        "                              #\n",
        "                              # Filter\n",
        "                              #   Only include the source in the final list if\n",
        "                              #   it has a valid URI\n",
        "                              #   This prevents showing incomplete or non-web\n",
        "                              #   sources to the user\n",
        "                              #\n",
        "                              if groundingAttributions.get('web', {}).get('uri')\n",
        "                            ]\n",
        "      #\n",
        "      # Return the model's text response and the list of sources\n",
        "      #\n",
        "      return chatResultText, chatResultSources\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "      #\n",
        "      # ENHANCED: Better error reporting for debugging\n",
        "      #\n",
        "      errorStatus = chatResponse.status_code if 'chatResponse' in locals() else 'Unknown'\n",
        "      errorText   = chatResponse.text if 'chatResponse' in locals() else 'No response text'\n",
        "\n",
        "      #\n",
        "      # Log the error details for the developer/debugger\n",
        "      #\n",
        "      print(f\"DEBUG: HTTP Error {errorStatus} encountered.\")\n",
        "      print(f\"DEBUG: Status Code: {errorStatus}. Details: {errorText[:200]}...\")\n",
        "\n",
        "      # print(f\"HTTP Error {errorStatus}: {e}\")\n",
        "      # print(f\"HTTP Error {errorStatus}: {str(e).replace(API_KEY, '')}\")\n",
        "      # print(f\"Error details: {errorText[:200]}...\")  # First 200 chars for context\n",
        "\n",
        "      #\n",
        "      # Handle API-Side Errors\n",
        "      # (e.g., 400 Bad Request, 429 Rate Limit, 500 Internal Server Error)\n",
        "      #\n",
        "      # print(f\"HTTP Error: {e}. Status Code: {chatResponse.status_code}\")\n",
        "\n",
        "      # #\n",
        "      # # Special handling for 400 errors (likely grounding issues)\n",
        "      # #\n",
        "      # if errorStatus == 400:\n",
        "      #   return \"I apologize, but there was an issue with the search. Please try rephrasing your question.\", []\n",
        "\n",
        "      # #\n",
        "      # # Non-Retryable Errors (like a bad API key or bad request)\n",
        "      # #\n",
        "      # if chatResponse.status_code < 500 and chatResponse.status_code != 429:\n",
        "      #   return f\"Fatal Client Error: {str(e).replace(API_KEY, '')}\", []\n",
        "      #\n",
        "      # Standardized Error Returns based on status code\n",
        "      #\n",
        "      if errorStatus == 400:\n",
        "        #\n",
        "        # 400 is often a bad request (e.g., bad format, too complex query)\n",
        "        #\n",
        "        return \"ERROR_BAD_REQUEST: I apologize, but there was an issue with the search query. Please try rephrasing your question.\", []\n",
        "      elif errorStatus == 429:\n",
        "        #\n",
        "        # 429 is rate limiting\n",
        "        # Note: This error is often transient and should be handled by the retry loop\n",
        "        #\n",
        "        pass # Let the retry loop handle this\n",
        "      elif errorStatus < 500:\n",
        "        #\n",
        "        # Other 4xx errors (like 401/403 if API key expired or unauthorized)\n",
        "        #\n",
        "        return f\"ERROR_CLIENT: Non-retryable Client Error {errorStatus} received. Please check API key status.\", []\n",
        "      #\n",
        "      # 5xx errors (server-side, should be retried) fall through to the backoff logic\n",
        "      #\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      #\n",
        "      # Handle Connectivity / Network Errors, Timeouts, etc.\n",
        "      #\n",
        "      # This is a general connection error, let the retry loop handle it\n",
        "      #\n",
        "      print(f\"DEBUG: Network Request failed: {str(e).replace(API_KEY, '')}\")\n",
        "      pass\n",
        "\n",
        "    #\n",
        "    # Exponential Backoff Logic\n",
        "    #\n",
        "\n",
        "    #\n",
        "    # If it's not the final attempt, calculate the delay and wait\n",
        "    #\n",
        "    if attempt < maxRetries - 1:\n",
        "      #\n",
        "      # Delay grows exponentially (2^0, 2^1, 2^2, ...)\n",
        "      #\n",
        "      delayProcess = 2 ** attempt\n",
        "\n",
        "      print(f\"DEBUG: Retrying in {delayProcess} seconds...\")\n",
        "      time.sleep(delayProcess)\n",
        "    else:\n",
        "      #\n",
        "      # If the final attempt failed, return the standardized maximum retry error\n",
        "      #\n",
        "      return \"ERROR_MAX_RETRIES: API call failed after maximum retries due to persistent network issues.\", []\n",
        "\n",
        "  #\n",
        "  # Should be unreachable if the final else block is hit,\n",
        "  # but included here for completeness\n",
        "  #\n",
        "  return \"ERROR_UNKNOWN: An unknown error occurred outside the retry loop.\", []"
      ],
      "metadata": {
        "id": "maU2GUayv9UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run ChatBot**"
      ],
      "metadata": {
        "id": "ACEeHRr9Rj2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`runChatBot(siteURL)`**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This function is the **application entry point and control loop**. It manages the state of the conversation and interacts with the user.\n",
        "\n",
        "**A. Purpose**\n",
        "\n",
        "To initialize the conversation, continuously accept user input, call the `generateContentWithRetry` function, and cleanly display the results and citations to the user until they decide to quit.\n",
        "\n",
        "**B. Conversation Loop**\n",
        "\n",
        "1.  **User Input:** It uses a `while True:` loop to repeatedly prompt the user for a question (`You: `).\n",
        "2.  **Exit Condition:** The loop breaks if the user types `quit` or `exit` or `terminate` or `bye`.\n",
        "3.  **API Call:** For every valid user query, it calls `generateContentWithRetry()`.\n",
        "4.  **Display Results:**\n",
        "    * The model's **response text** is printed immediately.\n",
        "    * If the API response includes **citations** (grounding sources), they are formatted and printed underneath the answer, allowing the user to click the links and verify the information.\n",
        "\n",
        "**C. Initialization**\n",
        "\n",
        "The function starts by defining the fixed `siteURL` and printing a welcoming `system_message`, clearly communicating the bot's persona (\"Devi\") and its limited knowledge domain.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mrpf30YWv_ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def runChatBot(siteURL):\n",
        "  #\n",
        "  # The application entry point and control loop.\n",
        "  #\n",
        "  # Initializes the conversation, accepts user input, calls the grounded API,\n",
        "  # and displays the results and citations until the user quits.\n",
        "  #\n",
        "  # Parameters:\n",
        "  #   siteURL: The URL of the website to ground the answers (e.g., 'srilalithambigaitemple.co.uk').\n",
        "  #\n",
        "\n",
        "  #\n",
        "  # System prompt to guide the model's behavior and personality\n",
        "  #\n",
        "  # SYSTEM_PROMPT = textwrap.dedent(\n",
        "  #                                  f\"\"\"\n",
        "  #                                    You are the AI assistant Devi, specializing in the {siteURL} website.\n",
        "  #                                    Your primary goal is to provide helpful and accurate information based ONLY on the search results you are provided, which are grounded to site:{siteURL}.\n",
        "  #                                    If you cannot find the answer on the website, state clearly that the information is not available on the official website.\n",
        "  #                                    Answer in a friendly, respectful, and informative tone.\n",
        "  #                                    Keep answers concise, usually 1-3 paragraphs.\n",
        "  #                                   \"\"\"\n",
        "  #                                ).strip()\n",
        "\n",
        "  systemPrompt = textwrap.dedent(GENERIC_PROMPT.replace(\"##SITE_URL##\", siteURL)).strip()\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"=== üïâÔ∏è Devi: Sri Lalithambigai Temple AI Assistant ===\")\n",
        "  print(\"\")\n",
        "  print(f\"Context: Answers are grounded to: {siteURL}\")\n",
        "  print(\"Ask me anything about the temple (e.g., 'What are the opening times?' or 'How do I donate?').\")\n",
        "  print(\"Type 'exit' or 'quit' or 'terminate' or 'bye' to end the session.\")\n",
        "  print(\"\")\n",
        "\n",
        "  while True:\n",
        "    try:\n",
        "      userInput = input(\"You : \")\n",
        "      if userInput.lower() in ['exit', 'quit', 'terminate', 'bye']:\n",
        "        print(\"Thank you for using the Devi Assistant. Goodbye!\")\n",
        "        break\n",
        "\n",
        "      if not userInput.strip():\n",
        "        continue\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Assistant (Devi) : Searching and generating response...\")\n",
        "\n",
        "      #\n",
        "      # Augment the user's prompt to force site-specific search grounding\n",
        "      # The siteURL parameter is crucial here for the grounding operator\n",
        "      #\n",
        "      # CRITICAL FIX: Augment the user's prompt to force location context\n",
        "      # This ensures the model's intent is highly specific before the search,\n",
        "      # reducing confusion with the India-based temple.\n",
        "      #\n",
        "      # searchQuery = f\"{userInput} site:{siteURL}\"\n",
        "      searchQuery = f\"Birmingham UK Sri Lalithambigai Temple {userInput} site:{siteURL}\"\n",
        "\n",
        "      #\n",
        "      # Build the payload for the API call\n",
        "      # The tools and systemInstruction fields are now top-level\n",
        "      # for standard API structure.\n",
        "      #\n",
        "      # payload\n",
        "      #   This dictionary tells the Gemini API:\n",
        "      #\n",
        "      #   \"Here is the user's question, and please use the Google Search tool,\n",
        "      #    constrained to the specified website, and use this specific personality\n",
        "      #    (systemPrompt) when answering\"\n",
        "      #\n",
        "      payload = {\n",
        "                  #\n",
        "                  # 'contents' holds the conversation history or\n",
        "                  # the current user query\n",
        "                  #\n",
        "                  \"contents\" : [\n",
        "                                 {\n",
        "                                   #\n",
        "                                   # 'parts' is an array of content blocks\n",
        "                                   # (text, images, etc.)\n",
        "                                   #\n",
        "                                   \"parts\" : [\n",
        "                                               #\n",
        "                                               # The augmented query is the main input\n",
        "                                               #\n",
        "                                               {\"text\" : searchQuery}\n",
        "                                             ]\n",
        "                                 }\n",
        "                               ],\n",
        "                  #\n",
        "                  # 'tools' is used to enable grounded generation (Google Search)\n",
        "                  # The empty object {} tells the model to perform a search\n",
        "                  # based on the content of the prompt.\n",
        "                  #\n",
        "                  \"tools\" : [\n",
        "                              {\n",
        "                                \"google_search\": {}\n",
        "                              }\n",
        "                            ], # Activates grounding\n",
        "                  #\n",
        "                  # 'systemInstruction' defines the model's\n",
        "                  # personality, tone, and constraints\n",
        "                  #\n",
        "                  \"systemInstruction\" : {\n",
        "                                          \"parts\" : [\n",
        "                                                      #\n",
        "                                                      # The specific instruction for the model\n",
        "                                                      # (e.g., personality and rules)\n",
        "                                                      #\n",
        "                                                      {\"text\" : systemPrompt}\n",
        "                                                    ]\n",
        "                                        },\n",
        "                  #\n",
        "                  # ENHANCED: Added generation config for more factual responses\n",
        "                  #\n",
        "                  \"generationConfig\" : {\n",
        "                                         \"temperature\"     : 0.1,  # Lower for more factual responses\n",
        "                                         \"topK\"            : 40,   # Limits to most probable tokens\n",
        "                                         \"topP\"            : 0.8,  # Dynamic pool, adapts to confidence\n",
        "                                         \"maxOutputTokens\" : 1024\n",
        "                                       }\n",
        "                }\n",
        "\n",
        "      # +-----------+------------------------------------------------------------+-----------------------------------------+---------------------------------------------------------+\n",
        "      # | Parameter | If Increased                                               | If Decreased                            | Behavior Effect                                         |\n",
        "      # +-----------+------------------------------------------------------------+-----------------------------------------+---------------------------------------------------------+\n",
        "      # | topK      | More tokens considered, more diversity and creativity,     | Fewer tokens considered, output         | Increasing topK lets the model explore rarer words;     |\n",
        "      # |           | but possibly less focused                                  | is safer, more predictable,             | decreasing keeps output conservative and focused        |\n",
        "      # |           |                                                            | or repetitive                           |                                                         |\n",
        "      # +-----------+------------------------------------------------------------+-----------------------------------------+---------------------------------------------------------+\n",
        "      # | topP      | Larger probability threshold, more randomness              | Smaller probability, output is          | Higher topP means broader pool, more randomness;        |\n",
        "      # |           | and variety, allows model to explore                       | focused and repetitive                  | lower topP restricts options and keeps output on-topic  |\n",
        "      # |           | more possible words                                        |                                         |                                                         |\n",
        "      # +-----------+------------------------------------------------------------+-----------------------------------------+---------------------------------------------------------+\n",
        "\n",
        "      #\n",
        "      # Call the API\n",
        "      #\n",
        "      generatedText, generatedSources = generateContentWithRetry(payload)\n",
        "\n",
        "      #\n",
        "      # Display the result\n",
        "      #\n",
        "      # print(f\"\\nAssistant (Devi) : {generatedText}\")\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"üïâÔ∏è Assistant (Devi)\")\n",
        "      print(\"=\" * 100)\n",
        "\n",
        "      #\n",
        "      # ENHANCEMENT: Check for the error prefix for user-friendly display\n",
        "      #\n",
        "      if generatedText.startswith(\"ERROR_\"):\n",
        "        #\n",
        "        # Split the error code and the technical message\n",
        "        #\n",
        "        errorCode, technicalMessage = generatedText.split(\":\", 1)\n",
        "\n",
        "        print(\"üö® **I apologize, but I've encountered an issue while trying to find that information.**\")\n",
        "\n",
        "        #\n",
        "        # Provide a user-friendly message based on the type of error\n",
        "        #\n",
        "        errorCode = errorCode.strip()\n",
        "\n",
        "        if errorCode == \"ERROR_API_KEY\":\n",
        "          friendlyMessage = \"It seems my connection to the system is not authorized. Please ensure the API key is set correctly.\"\n",
        "        elif errorCode == \"ERROR_MAX_RETRIES\":\n",
        "          friendlyMessage = \"I am currently unable to reach the temple's website or the network is unstable. Please try asking again in a few moments.\"\n",
        "        elif errorCode == \"ERROR_BAD_REQUEST\":\n",
        "          friendlyMessage = \"I'm having trouble processing that specific query. Could you try rephrasing your question more simply?\"\n",
        "        else: # Covers ERROR_CLIENT and ERROR_UNKNOWN\n",
        "          friendlyMessage = \"An unexpected connection issue occurred. I cannot fetch information right now.\"\n",
        "\n",
        "        #\n",
        "        # Display the friendly message to the user\n",
        "        #\n",
        "        wrappedFriendlyMessage = textwrap.fill(friendlyMessage, width = 100)\n",
        "        print(wrappedFriendlyMessage)\n",
        "        print(\"\")\n",
        "        print(f\"*(Technical detail - {errorCode} : {technicalMessage.strip()})*\")\n",
        "      else:\n",
        "        wrappedText = textwrap.fill(generatedText, width = 100)\n",
        "\n",
        "        print(wrappedText)\n",
        "        print(\"=\" * 100)\n",
        "        print(\"\")\n",
        "\n",
        "        #\n",
        "        # Display the citations\n",
        "        #\n",
        "        if generatedSources:\n",
        "          print(\"\\n\\n--- Knowledge Sources (Grounding) ---\")\n",
        "\n",
        "          #\n",
        "          # The Starting Index\n",
        "          #\n",
        "          # The number 1 is the optional start argument for the enumerate() function.\n",
        "          # By default, enumerate() starts counting from 0.\n",
        "          # For example, if we just wrote enumerate(sources),\n",
        "          # the index i would be 0, 1, 2, 3, ....\n",
        "          #\n",
        "          # When we provide 1 as the second argument, we tell enumerate()\n",
        "          # to start the index count at 1 instead of 0\n",
        "          #\n",
        "          # Why Start at 1?\n",
        "          #\n",
        "          # This is extremely common when dealing with output for a human reader,\n",
        "          # especially for lists, steps, or, in your case, citations/sources\n",
        "          #\n",
        "          # By starting at 1, the sources are numbered 1, 2, 3, ... which is\n",
        "          # much more natural and user-friendly than starting a list with 0\n",
        "          #\n",
        "          for i, generatedSource in enumerate(generatedSources, 1):\n",
        "            #\n",
        "            # Use textwrap to format long titles and URIs neatly\n",
        "            #\n",
        "            formattedTitle = textwrap.fill(generatedSource.get('title', 'No Title'), subsequent_indent = ' ' * (len(str(i)) + 3))\n",
        "            print(f\"{i}. {formattedTitle}\")\n",
        "            print(f\"   URI: {generatedSource.get('uri', 'N/A')}\")\n",
        "\n",
        "          print(\"-\" * 100)\n",
        "          print(\"\")\n",
        "        else:\n",
        "          print(\"\\n(No specific sources found to cite for this answer)\\n\")\n",
        "\n",
        "      print(\"=\" * 100)\n",
        "      print(\"\")\n",
        "    except KeyboardInterrupt:\n",
        "      print(\"\\nThank you for using the Devi assistant. Goodbye!\")\n",
        "      break\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred in the chat loop: {str(e).replace(API_KEY, '')}\")\n",
        "      break"
      ],
      "metadata": {
        "id": "DmtbbP0QyJCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Execute ChatBot**"
      ],
      "metadata": {
        "id": "12VaO3rY5r9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Execution block to run the Chatbot\n",
        "#\n",
        "if __name__ == \"__main__\":\n",
        "  #\n",
        "  # Define the specific site URL for grounding\n",
        "  #\n",
        "  runChatBot(TEMPLE_SITE_URL)"
      ],
      "metadata": {
        "id": "KfitWe4W5vt4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
